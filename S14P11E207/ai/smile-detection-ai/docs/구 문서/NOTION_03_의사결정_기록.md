# 의사결정 기록 (Decision Log)

프로젝트 진행 중 내린 모든 중요한 결정을 기록합니다.

---

# Decision 1: 모델 아키텍처 선택

날짜: 2026-01-12
결정 사항: CNN + LSTM Hybrid 모델 채택

## 고려한 옵션

| 옵션 | 장점 | 단점 | 선택 |
|------|------|------|------|
| A. CNN 단독 | 매우 빠름 (200+ FPS) | 시간적 패턴 학습 불가 | ❌ |
| **B. CNN + LSTM** | **빠르고 시간 패턴 학습 가능** | **중간 복잡도** | **✅** |
| C. Transformer (ViT) | 최고 성능 | 느림, 많은 데이터 필요 | ❌ |
| D. 3D CNN | 공간+시간 학습 | 무거움, 느림 | ❌ |

---

## 선택 이유: Option B (CNN + LSTM)

### 1. 실시간 성능 요구사항 충족

**목표**: 30 FPS (33ms/프레임)

결과:
- CNN + LSTM: 5-15ms/프레임 ✅
- Transformer: 30-100ms/프레임 ❌

### 2. 웃음 감지 특성

웃음 특성:
- 지속 시간: 0.5~2초
- 프레임 수: 15~60 프레임 (30 FPS 기준)

분석:
- 짧은 시퀀스에는 LSTM이 최적
- Transformer는 긴 컨텍스트(수백 프레임)에서 강점
- 우리 케이스에는 오버킬

### 3. 데이터 효율성

요구 데이터량:
- Transformer: 수십만~수백만 샘플
- CNN + LSTM: 수만 샘플

우리 계획:
- 자체 데이터 수집 (약 43만 프레임)
- CNN + LSTM으로 충분

### 4. 연산 복잡도

| 방식 | 복잡도 | 설명 |
|------|--------|------|
| LSTM | O(n) | n=10이면 충분히 빠름 |
| Transformer | O(n²) | 작은 n에도 오버헤드 |

### 5. 모델 크기

| 모델 | 크기 | 영향 |
|------|------|------|
| CNN + LSTM | 10-50MB | 다중 사용자 처리 유리 |
| Transformer | 100-500MB+ | 메모리 부담 |

---

## 트레이드오프

**포기한 것**:
- Transformer의 최고 성능 (예상 2-3% 정확도 차이)
- Long-range dependency 학습 능력 (우리 케이스에 불필요)

**얻은 것**:
- 실시간 처리 가능
- 적은 데이터로도 학습 가능
- 경량화 및 배포 용이성

---

## 검증 계획

Ablation Study로 LSTM의 기여도 확인:
- Baseline (CNN only): 예상 75%
- CNN + LSTM: 예상 85%+
- 차이가 5% 미만이면 재검토

---

# Decision 2: CNN Backbone 선택

날짜: 2026-01-12
결정 사항: MobileNetV3-Small 채택

## 고려한 옵션

| Backbone | 파라미터 | 크기 | 속도 | ImageNet Top-1 | 선택 |
|----------|---------|------|------|---------------|------|
| **MobileNetV3-Small** | **2.5M** | **2.5MB** | **200+ FPS** | **67.4%** | **✅** |
| MobileNetV3-Large | 5.4M | 5.5MB | 150 FPS | 75.2% | ⭐ 대안 |
| EfficientNet-B0 | 5.3M | 20MB | 80 FPS | 77.1% | ❌ |
| ResNet18 | 11M | 45MB | 100 FPS | 69.8% | ❌ |

---

## 선택 이유: MobileNetV3-Small

### 1. 속도 우선

200+ FPS → 10프레임 처리해도 여유
- 실시간 처리 보장
- 추가 최적화 여지

### 2. 충분한 성능

ImageNet 67.4%:
- 얼굴 표정 인식에 충분
- Transfer Learning으로 성능 향상
- Pretrained 가중치 활용

### 3. 경량화

2.5MB 크기:
- 메모리 효율적
- 다중 사용자 처리 유리
- 서버 리소스 절약

### 4. 확장성

향후 계획:
- 모바일 앱 개발 시 사용 가능
- Edge Device 배포 가능
- 최소 수정으로 이식

---

## 대안 고려: MobileNetV3-Large

언제 업그레이드할지:
- Small로 목표 성능(85%) 미달 시
- 서버 리소스 충분히 확보 시
- 정확도가 속도보다 중요해질 시

---

# Decision 3: 데이터 전략

날짜: 2026-01-12
결정 사항: 3단계 하이브리드 접근

## 선택한 전략

### Phase 1: Pretrain (공개 데이터셋)

데이터: AffectNet + FER2013
목적: 기본 표정 특징 학습
예상 성능: 70-80%

### Phase 2: Fine-tune (한국인 자체 수집)

데이터: 20-30명, 약 43만 프레임
목적: 도메인 적응 (한국인 얼굴)
예상 성능: 85-90%

### Phase 3: Active Learning (지속 개선)

데이터: 실사용 중 오류 케이스
목적: 지속적 성능 향상

---

## 왜 하이브리드인가?

### 다른 옵션들

**공개 데이터만**:
- 장점: 빠르게 시작
- 단점: 한국인 정확도 낮음 (예상 75%)

**자체 수집만**:
- 장점: 정확함
- 단점: 시간 오래 걸림 (2-3주)

**하이브리드** ✅:
- 장점: 빠르게 시작 + 높은 정확도
- 단점: 단계별 작업 필요

---

## 한국인 데이터 중요성

### 근거

**1. 얼굴 구조 차이**
- 동양인 vs 서양인
- 눈꺼풀 구조, 광대뼈 위치

**2. 표정 표현 차이**
- 눈웃음 vs 활짝 웃음
- 입 모양 변화 패턴

**3. 문화적 차이**
- 억제된 미소
- 손으로 입 가리는 습관

---

## AI Hub 조사 필요

한국 정부 AI 데이터 포털:
- "감정 인식" 데이터셋 검색
- "얼굴 표정" 데이터셋 검색

결과:
- 있으면 활용
- 없으면 자체 수집

---

# Decision 4: 시퀀스 길이

날짜: 2026-01-12
결정 사항: 10 프레임 (약 0.33초 @ 30fps)

## 고려한 옵션

| 시퀀스 길이 | 시간 | 장점 | 단점 | 선택 |
|-----------|------|------|------|------|
| 5 프레임 | 0.17s | 빠른 반응 | 웃음 오감지 가능 | ❌ |
| **10 프레임** | **0.33s** | **균형** | **없음** | **✅** |
| 15 프레임 | 0.5s | 높은 정확도 | 느린 반응 | ❌ |
| 20 프레임 | 0.67s | 매우 정확 | 게임 불공평 | ❌ |

---

## 선택 근거: 10 프레임

### 1. 웃음 감지 충분성

웃음 지속 시간:
- 자연스러운 웃음: 0.5~2초
- 0.33초면 웃음 시작 감지 가능

### 2. 게임 공정성

너무 빠름 (5 프레임):
- 거짓 양성 많음 → 억울함

너무 느림 (15+ 프레임):
- 웃음 놓침 → 불공평

10 프레임:
- 적절한 균형

### 3. LSTM 효율성

10 timesteps:
- LSTM이 빠르게 처리
- Gradient vanishing 문제 없음
- 충분한 시간적 패턴 학습

---

## 실험으로 검증

계획:
- [5, 10, 15] 프레임으로 각각 학습
- Validation set에서 F1 score 비교
- 사용자 테스트로 체감 반응 속도 확인

---

# Decision 5: LSTM 설정

날짜: 2026-01-12
결정 사항: 2-layer Bidirectional LSTM, Hidden=128

## 구성

설정:
- input_size: 256
- hidden_size: 128
- num_layers: 2
- bidirectional: True
- dropout: 0.2

---

## Hidden Size: 128

### 고려 옵션

| 크기 | 장점 | 단점 | 선택 |
|------|------|------|------|
| 64 | 빠름 | 표현력 부족 | ❌ |
| **128** | **성능과 속도 균형** | **없음** | **✅** |
| 256 | 높은 표현력 | 과적합 위험 | ❌ |

---

## Num Layers: 2

### 고려 옵션

| 레이어 수 | 특징 | 선택 |
|----------|------|------|
| 1 | 단순한 패턴만 학습 | ❌ |
| **2** | **계층적 시간 패턴 학습** | **✅** |
| 3 | 복잡하지만 학습 어려움 | ❌ |

---

## Bidirectional: True

### 이유

웃음 패턴:
- 시작과 끝이 모두 중요
- Forward: 웃음 시작 감지
- Backward: 웃음 끝 확인

효과:
- 양방향 정보로 정확도 향상
- 예상 +3~5%

---

## 트레이드오프

**비용**:
- 파라미터 2배 증가
- 추론 시간 +20%

**이득**:
- 여전히 실시간 가능 (15ms 정도)
- 정확도 향상

**결론**: 이득이 비용보다 큼

---

# Decision 6: 학습 전략

날짜: 2026-01-12
결정 사항: 2-Phase Training

## Phase 1: Freeze Backbone

설정:
- Backbone freeze
- Classifier만 학습
- Epochs: 10
- Learning rate: 1e-3

이유:
- Pretrained 특징 보존
- Classifier 빠르게 학습
- 과적합 방지

---

## Phase 2: Unfreeze All

설정:
- 전체 fine-tuning
- Epochs: 30-40
- Learning rate: 1e-4 (10배 감소)

이유:
- 도메인 적응 (얼굴 표정에 최적화)
- End-to-end 학습
- 낮은 LR로 조심스럽게 조정

---

## Learning Rate Scheduler: Cosine Annealing

설정:
- T_max: 50
- eta_min: 1e-6

선택 이유:

**StepLR**: 급격한 변화, 불안정

**Cosine** ✅: 부드러운 감소, 수렴 안정

**ReduceLROnPlateau**: 수동 조정 필요

---

# Decision 7: 손실 함수 및 클래스 불균형

날짜: 2026-01-12
결정 사항: Weighted CrossEntropyLoss

## 예상 클래스 분포

비웃음: 70% (300,000 프레임)
웃음: 30% (130,000 프레임)

---

## 가중치 계산

클래스별 가중치:
- 비웃음 (다수): 1.0
- 웃음 (소수): 300/130 = 2.3

적용: CrossEntropyLoss(weight=[1.0, 2.3])

---

## 대안 고려

| 방법 | 장점 | 단점 | 선택 |
|------|------|------|------|
| No weighting | 간단 | 다수 클래스 편향 | ❌ |
| **Class weighting** | **균형잡힌 학습** | **없음** | **✅** |
| Focal Loss | 어려운 샘플 집중 | 복잡함 | 나중에 고려 |
| Oversampling | 데이터 균형 | 과적합 위험 | 보조 수단 |

---

# Decision 8: 데이터 증강

날짜: 2026-01-12
결정 사항: 화상통화 환경 특화 증강

## 증강 기법

### 기하학적

- horizontal_flip: 0.5
- rotation: ±15도
- scale: 0.9 ~ 1.1

### 색상/조명

- brightness: 0.8 ~ 1.2
- contrast: 0.8 ~ 1.2

### 화상통화 특화

- jpeg_compression: 70-100
- gaussian_noise: σ=0.01

---

## 선택 이유

### 포함된 증강

**Horizontal flip**:
- 얼굴 좌우 대칭
- 자연스러움

**Rotation**:
- 고개 기울임 (자연스러운 자세)
- ±15도 범위

**Brightness**:
- 조명 변화 (창문, 전등)
- 화상통화 실제 환경

**JPEG compression**:
- 웹캠 압축 아티팩트
- 현실적 노이즈

---

## 제외된 증강

**Vertical flip**: 부자연스러움 ❌

**Heavy rotation (>15°)**: 비현실적 ❌

**CutOut**: 얼굴 일부 가림 → 혼란 ❌

**Grayscale**: 컬러 정보 손실 ❌

---

## 검증

비교 실험:
- Augmentation 있음 vs 없음
- 예상: +3~5% 정확도 향상
- 과적합 감소 확인

---

# Decision 9: 평가 지표 우선순위

날짜: 2026-01-12
결정 사항: Recall > Precision

## 우선순위

1. Recall (재현율): 90%+ 목표 ⭐⭐⭐⭐⭐
2. Precision (정밀도): 85%+ 목표 ⭐⭐⭐⭐
3. F1 Score: 87%+ 목표 ⭐⭐⭐⭐
4. Inference Time: <30ms ⭐⭐⭐⭐⭐

---

## 근거: Recall이 가장 중요한 이유

### 게임 공정성 관점

**시나리오 1: False Negative (Recall 문제)**

실제: 웃음 😊
예측: 비웃음
결과: 웃었는데 감지 못함 → 게임 불공평! ❌❌❌

**시나리오 2: False Positive (Precision 문제)**

실제: 비웃음 😐
예측: 웃음
결과: 억울하지만 조심하면 됨 → 상대적으로 덜 심각 ⚠️

---

## 임계값 조정

기본 임계값: 0.5
- if prob_smile > 0.5: predict_smile = True

Recall 높이기: 임계값 낮춤
- if prob_smile > 0.4: predict_smile = True
- 더 민감하게 감지

---

## 목표 Confusion Matrix

균형 잡힌 목표:

예측
- No: [1700, 300]
- Yes: [100, 900]

결과:
- Recall = 90%
- Precision = 75%

현실적이고 게임에 적합

---

# Decision 10: API 설계

날짜: 2026-01-12
결정 사항: REST API + 서버 측 프레임 버퍼링

## API 방식 비교

| 방식 | 장점 | 단점 | 선택 |
|------|------|------|------|
| **REST (POST)** | **간단, Stateless** | **약간의 오버헤드** | **✅** |
| WebSocket | 낮은 레이턴시 | 복잡함 | 나중에 |
| gRPC | 빠름 | 설정 복잡 | ❌ |

---

## REST API 선택 이유

### 1. 팀원 구현 용이

- 익숙한 기술
- 디버깅 쉬움 (Postman 등)
- 문서화 자동 (FastAPI)

### 2. 확장성

- 로드 밸런서 적용 쉬움
- Stateless (서버 스케일링 용이)

### 3. 충분한 성능

- HTTP/2로 충분히 빠름
- 30 FPS 처리 가능

---

## 서버 측 버퍼링

### 문제

LSTM은 10프레임 필요
클라이언트는 1프레임씩 전송

### 해결

각 사용자별로 최근 10프레임 큐 유지:
- user_123: deque(maxlen=10)
- user_456: deque(maxlen=10)

동작:
1. 새 프레임 도착
2. 버퍼에 추가 (자동으로 오래된 것 제거)
3. 10프레임 있으면 예측
4. 없으면 "warming up" 응답

---

## 대안 (미채택)

**클라이언트 버퍼링**: 복잡도 증가 ❌

**Stateful LSTM**: 상태 관리 어려움 ❌

---

# Decision 11: 모델 최적화 전략

날짜: 2026-01-12
결정 사항: TorchScript + Mixed Precision

## 단계별 최적화

### Phase 1: TorchScript (필수)

방법: torch.jit.trace()
예상 효과: 10-20% 속도 향상

### Phase 2: Mixed Precision (선택)

방법: torch.cuda.amp.autocast()
예상 효과:
- 20-30% 속도 향상
- 50% 메모리 절약

### Phase 3: ONNX (필요 시)

방법: torch.onnx.export()
용도: CPU 추론 시 유용

---

## Quantization (보류)

INT8 양자화:
- 속도: 2배 향상
- 메모리: 4배 절약
- 정확도: 1-2% 감소

결정: 일단 FP32로 시작, 성능 부족 시 고려

---

# 🎯 남은 의사결정

## 데이터 관련

- [ ] AI Hub에서 한국인 데이터셋 찾기
- [ ] 못 찾으면 자체 수집 참가자 모집 방법
- [ ] 라벨링 도구 선택 (CVAT, LabelImg, 커스텀)

## 배포 관련

- [ ] 서버 환경 (AWS, GCP, On-premise)
- [ ] GPU 종류 (T4, V100, A100)
- [ ] Docker 이미지 베이스 선택

## 팀 협업

- [ ] API 스펙 최종 확인
- [ ] 프레임 전송 포맷 (JPEG quality, resize 여부)
- [ ] 에러 처리 방식

---

작성자: AI 모델 개발자
최종 업데이트: 2026-01-12
